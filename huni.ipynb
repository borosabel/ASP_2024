{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-20T16:47:22.029276Z",
     "start_time": "2024-05-20T16:47:22.026807Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from os import path\n",
    "import pickle\n",
    "\n",
    "import models\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import models\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import data\n",
    "import mir_eval\n",
    "import pickle\n",
    "import glob\n",
    "from os import path\n",
    "import json\n",
    "\n",
    "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "\n",
    "with open('dataset-stats.pkl', 'rb') as f:\n",
    "    stats = pickle.load(f)\n",
    "    mean = th.Tensor(stats['mean']).to(device)\n",
    "    std = th.Tensor(stats['std']).to(device)\n",
    "\n",
    "@th.no_grad()\n",
    "def onset_signal(model, x):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    x = x.to(device)\n",
    "    x = (x - mean)/std\n",
    "    x = x.unsqueeze(0)\n",
    "    out = th.sigmoid(model(x)).detach().cpu()\n",
    "    out = np.convolve(out[0], np.hamming(5))\n",
    "\n",
    "    return out\n",
    "\n",
    "def onsets(onset_signal):\n",
    "    res = []\n",
    "    print(\"onset peak signal\", find_peaks(onset_signal)[0])\n",
    "    print(\"onset peak signal\", find_peaks(onset_signal)[0])\n",
    "    for idx in find_peaks(onset_signal)[0]:\n",
    "        if onset_signal[idx] >= 0.95:\n",
    "            res.append(idx * data.HOP_LENGTH / data.SAMPLE_RATE)\n",
    "\n",
    "    return np.array(res)\n",
    "\n",
    "def evaluate_onsets(model, X, y):\n",
    "    f_scores = []\n",
    "    for idx, x in enumerate(X):\n",
    "        pred = onsets(onset_signal(model, x))\n",
    "        f, _, _ = mir_eval.onset.f_measure(y[idx], pred, window=0.05)\n",
    "        f_scores.append(f)\n",
    "\n",
    "    return f_scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T22:00:59.468363Z",
     "start_time": "2024-05-20T22:00:59.464640Z"
    }
   },
   "id": "714a5d41a0e79476"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "FRAME_LENGTH = 15\n",
    "FRAME_HALF = 7\n",
    "HOP_LENGTH = 512\n",
    "WIN_LENGTHS = [1024, 2048, 4096]\n",
    "SAMPLE_RATE = 44100\n",
    "\n",
    "_transforms =[torchaudio.transforms.MelSpectrogram(SAMPLE_RATE, n_fft=wl, hop_length=HOP_LENGTH, n_mels=80, f_min=27.5, f_max=16000) for wl in WIN_LENGTHS]\n",
    "\n",
    "def make_frames(X, y, onsets, sample_rate):\n",
    "    X_frames, y_frames = [], []\n",
    "\n",
    "    for onset_time in onsets:\n",
    "        onset_idx = int(seconds_to_bins(onset_time, sample_rate))\n",
    "\n",
    "        start = max(0, onset_idx - FRAME_LENGTH//2)\n",
    "        end = min(onset_idx + FRAME_LENGTH//2 + 1, X.shape[2] - FRAME_LENGTH)\n",
    "\n",
    "        idx = start\n",
    "        while idx < end:\n",
    "            X_frames.append(X[:, :, idx:idx+FRAME_LENGTH])\n",
    "            y_frames.append(y[idx:idx+FRAME_LENGTH])\n",
    "            idx += 1\n",
    "\n",
    "    return X_frames, y_frames\n",
    "\n",
    "def make_target(onsets, length, sample_rate):\n",
    "    y = th.zeros(length)\n",
    "\n",
    "    for x in onsets:\n",
    "        x_t = int(seconds_to_bins(x, sample_rate))\n",
    "        y[x_t] = 1\n",
    "\n",
    "        if x_t - 1 >= 0 and y[x_t - 1] != 1:\n",
    "            y[x_t - 1] = 0.25\n",
    "\n",
    "        if x_t + 1 < length and y[x_t + 1] != 1:\n",
    "            y[x_t + 1] = 0.25\n",
    "\n",
    "    return y\n",
    "\n",
    "def seconds_to_bins(a, sample_rate):\n",
    "    return a * sample_rate / HOP_LENGTH\n",
    "\n",
    "def mel(waveform):\n",
    "    mel_specs = [transform(waveform) for transform in _transforms]\n",
    "    return th.log10(th.stack(mel_specs) + 1e-08)\n",
    "\n",
    "def load_onsets(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        onsets = list(map(float, f.read().split()))\n",
    "    return np.array(onsets)\n",
    "\n",
    "def preprocess_audio(files):\n",
    "    spectograms = []\n",
    "    sample_rates = []\n",
    "\n",
    "    for file_path in tqdm(files):\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        mel_specgram = mel(waveform[0])\n",
    "        spectograms.append(mel_specgram)\n",
    "        sample_rates.append(sample_rate)\n",
    "\n",
    "    return spectograms, sample_rates\n",
    "\n",
    "class AudioOnsetDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, spectograms, sample_rates, targets, sample_onsets):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for X, sample_rate, y, onsets in zip(spectograms, sample_rates, targets, sample_onsets):\n",
    "            X_frames, y_frames = make_frames(X, y, onsets, sample_rate)\n",
    "            print(X_frames[0].shape)\n",
    "            self.X += X_frames\n",
    "            self.y += y_frames\n",
    "\n",
    "        tmp = th.cat(self.X)\n",
    "        self.mean = th.mean(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "        self.std = th.std(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "        del tmp\n",
    "\n",
    "        self.X = [(x - self.mean)/self.std for x in self.X]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T22:00:59.615512Z",
     "start_time": "2024-05-20T22:00:59.600182Z"
    }
   },
   "id": "1c1138accf8c3446"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "train_path = './data/onset/train_extra_onsets'\n",
    "X_files = glob.glob(path.join(train_path, '*.wav'))\n",
    "y_files = glob.glob(path.join(train_path, '*.onsets.gt'))\n",
    "print(len(X_files))\n",
    "\n",
    "X_files_train, X_files_test, y_files_train, y_files_test = train_test_split(X_files, y_files, test_size=0.2, random_state=42)\n",
    "print(len(X_files_train), len(X_files_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T22:00:59.736327Z",
     "start_time": "2024-05-20T22:00:59.731501Z"
    }
   },
   "id": "fc7e07137e342cc3"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "['./data/onset/train_extra_onsets/ah_development_guitar_2684_TexasMusicForge_Dandelion_pt1.wav']"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_files_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T22:00:59.880427Z",
     "start_time": "2024-05-20T22:00:59.874495Z"
    }
   },
   "id": "6e626121b2c8c325"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.85it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, sample_rates_train = data.preprocess_audio(X_files_train)\n",
    "onsets_train = [data.load_onsets(path) for path in y_files_train]\n",
    "y_train = [data.make_target(onsets_train[i], X_train[i].shape[-1], sample_rates_train[i]) for i in range(len(onsets_train))]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T22:01:00.076528Z",
     "start_time": "2024-05-20T22:01:00.011696Z"
    }
   },
   "id": "7f481a5cd9fa63ba"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 77.64it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, sample_rates_test = data.preprocess_audio(X_files_test)\n",
    "onsets_test = [data.load_onsets(path) for path in y_files_test]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T22:01:00.159560Z",
     "start_time": "2024-05-20T22:01:00.142600Z"
    }
   },
   "id": "880541a07a0739f5"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 80, 15])\n"
     ]
    }
   ],
   "source": [
    "dataset = AudioOnsetDataset(X_train, sample_rates_train, y_train, onsets_train)\n",
    "\n",
    "with open('dataset-stats.pkl', 'wb') as f:\n",
    "    pickle.dump({ 'mean': dataset.mean, 'std': dataset.std }, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T22:01:00.293378Z",
     "start_time": "2024-05-20T22:01:00.273943Z"
    }
   },
   "id": "a68e96a5a6ca8b3f"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "lr = 3e-4\n",
    "\n",
    "train_dataloader = DataLoader(dataset, shuffle=True, batch_size=256)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T22:01:00.419538Z",
     "start_time": "2024-05-20T22:01:00.407401Z"
    }
   },
   "id": "add6997f889ce1d7"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "loss: 1.4471831321716309\n",
      "onset peak signal [  4  12  18  32  38  43  50  59  67  72  77  82  86  99 109 111 121 128\n",
      " 135 152 157 162 169 177 182 187 193 199 203 212 222 235 243 247 256 265\n",
      " 275 281 291 298 303 308 312 321 332 337 346 359 364 376 378 384 394 405\n",
      " 413 418 424 437 444 450 452 457 463 476 489 500 504 519 523 527 532 536\n",
      " 545 551 556 558 571 580 591 599 603 607 615 620 625 632 644 655 663 668\n",
      " 673 679 683 693 698 701 705 709 715 720 724 735 741 749 753 760 765 776\n",
      " 784 788 801 814 820 825 832 845]\n",
      "onset peak signal [  4  12  18  32  38  43  50  59  67  72  77  82  86  99 109 111 121 128\n",
      " 135 152 157 162 169 177 182 187 193 199 203 212 222 235 243 247 256 265\n",
      " 275 281 291 298 303 308 312 321 332 337 346 359 364 376 378 384 394 405\n",
      " 413 418 424 437 444 450 452 457 463 476 489 500 504 519 523 527 532 536\n",
      " 545 551 556 558 571 580 591 599 603 607 615 620 625 632 644 655 663 668\n",
      " 673 679 683 693 698 701 705 709 715 720 724 735 741 749 753 760 765 776\n",
      " 784 788 801 814 820 825 832 845]\n",
      "onset peak signal [  4  21  34  39  44  52  58  66  70  78  83  87  93 104 111 119 125 131\n",
      " 140 155 158 166 176 181 184 195 202 204 207 213 218 222 225 230 240 243\n",
      " 249 263 270 275 285 290 295 307 311 319 324 332 337]\n",
      "onset peak signal [  4  21  34  39  44  52  58  66  70  78  83  87  93 104 111 119 125 131\n",
      " 140 155 158 166 176 181 184 195 202 204 207 213 218 222 225 230 240 243\n",
      " 249 263 270 275 285 290 295 307 311 319 324 332 337]\n",
      "F-scores: TRAIN 0.5283018867924528 | TEST 0.4307692307692308\n",
      "epoch 2\n",
      "loss: 1.3665432929992676\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[133], line 24\u001B[0m\n\u001B[1;32m     21\u001B[0m loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mbinary_cross_entropy_with_logits(out, y, weight\u001B[38;5;241m=\u001B[39mmask, pos_weight\u001B[38;5;241m=\u001B[39mpos_weight)\n\u001B[1;32m     23\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 24\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_idx \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/lib/python3.9/site-packages/torch/_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    524\u001B[0m     )\n\u001B[0;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.9/site-packages/torch/autograd/__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.9/site-packages/torch/autograd/graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = models.Resi(3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "pos_weight = th.Tensor([14.]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "data_mean, data_std = dataset.mean.to(device), dataset.std.to(device)\n",
    "\n",
    "best_mean = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    print(f'epoch {epoch + 1}')\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # fuzzy weight mask\n",
    "        mask = th.ones_like(y)\n",
    "        mask[y == 0.25] = 0.25\n",
    "        y[y == 0.25] = 1.\n",
    "        out = model(X)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y, weight=mask, pos_weight=pos_weight)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'loss: {loss.item()}')\n",
    "\n",
    "    model.eval()\n",
    "    f_scores_train = evaluate_onsets(model, X_train, onsets_train)\n",
    "    f_scores_test = evaluate_onsets(model, X_test, onsets_test)\n",
    "    f_mean_test = np.mean(f_scores_test)\n",
    "    print(f'F-scores: TRAIN {np.mean(f_scores_train)} | TEST {np.mean(f_mean_test)}')\n",
    "\n",
    "    if f_mean_test > best_mean:\n",
    "        best_mean = f_mean_test\n",
    "        th.save(model.state_dict(), 'resi.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T22:01:03.684672Z",
     "start_time": "2024-05-20T22:01:00.570905Z"
    }
   },
   "id": "97542ad26adc0194"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-20T16:49:32.410216Z"
    }
   },
   "id": "3d8c7d5c6d435d5e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "50887e8ce69a3487"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
