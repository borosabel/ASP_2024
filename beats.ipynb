{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T15:10:45.912951Z",
     "start_time": "2024-05-30T15:10:45.850601Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils as utils\n",
    "import importlib\n",
    "import numpy as np\n",
    "import mir_eval\n",
    "import data\n",
    "import pickle\n",
    "import librosa\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(data)\n",
    "\n",
    "train_dataset_path = './data/train'\n",
    "test_dataset_path = './data/test'\n",
    "\n",
    "device = 'cuda' if th.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c18e722df1d707",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T15:10:46.068414Z",
     "start_time": "2024-05-30T15:10:46.064959Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model descrbied in the paper plus droput\n",
    "class OnsetDetectionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OnsetDetectionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=(3, 7))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=(3, 3))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 1))\n",
    "        self.fc1 = nn.Linear(20 * 7 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 20 * 7 * 8)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))  # Apply dropout\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = OnsetDetectionCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e794905b16b20c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T22:06:27.021326Z",
     "start_time": "2024-06-02T22:06:26.938357Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(th.load('best_model.pth'))\n",
    "with open('mean_std.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "mean = data['mean']\n",
    "std = data['std']\n",
    "\n",
    "# This is the almost the same as the prediction function in the onset detection but here we just use the onset signal \n",
    "# and no prediction\n",
    "def raw_onset_signal(model, x, mean=mean, std=std, frame_size=15):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    x = x.to(device)\n",
    "    mean = mean.to(device)\n",
    "    std = std.to(device)\n",
    "    x = (x - mean) / std\n",
    "\n",
    "    half_frame_size = frame_size // 2\n",
    "    num_frames = x.shape[2]\n",
    "    onset_predictions = []\n",
    "\n",
    "    with th.no_grad():\n",
    "        for j in range(half_frame_size, num_frames - half_frame_size):\n",
    "            start = j - half_frame_size\n",
    "            end = j + half_frame_size + 1\n",
    "            input_frame = x[:, :, start:end].unsqueeze(0).float()\n",
    "            output = model(input_frame).squeeze().cpu().item()\n",
    "            onset_predictions.append(output)\n",
    "    onset_predictions = np.array(onset_predictions)\n",
    "    onset_signal = np.convolve(onset_predictions, np.hamming(10), mode='same')\n",
    "    return onset_signal\n",
    "\n",
    "def autocorrelate(signal, lag):\n",
    "    r = np.zeros(len(signal) - lag)\n",
    "    for t in range(len(signal) - lag):\n",
    "        r[t] = signal[t + lag] * signal[t]\n",
    "    return np.sum(r)\n",
    "\n",
    "def to_bpm(max_r):\n",
    "    return 60 * utils.SAMPLING_RATE / utils.HOP_LENGTH / (max_r + 25)\n",
    "\n",
    "def autocorrelate_tao(signal, min_tao=25, max_tao=87):\n",
    "    return np.array([autocorrelate(signal, tao) for tao in range(min_tao, max_tao)])\n",
    "\n",
    "def get_tempo(model, x, top_n=2):\n",
    "    onset_signal_res = raw_onset_signal(model, x)\n",
    "    taos = autocorrelate_tao(onset_signal_res)\n",
    "    peaks = find_peaks(taos)[0]\n",
    "    highest_peaks = np.argsort(-taos[peaks])[:top_n]\n",
    "\n",
    "    return list(reversed([to_bpm(r) for r in peaks[highest_peaks]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ba2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def estimate_beats(onset_signal, tempo_bpm):\n",
    "#     # Convert tempo to frame period\n",
    "#     tempo_period = 60 / tempo_bpm * utils.SAMPLING_RATE / utils.HOP_LENGTH  # in frames\n",
    "#     max_lag = int(tempo_period * 1.5)\n",
    "#     min_lag = int(tempo_period * 0.5)\n",
    "    \n",
    "#     # Dynamic programming for beat tracking\n",
    "#     dp = np.zeros(len(onset_signal))\n",
    "#     backtrack = np.zeros(len(onset_signal), dtype=int)\n",
    "\n",
    "#     for t in range(min_lag, len(onset_signal)):\n",
    "#         max_score = -np.inf\n",
    "#         best_lag = 0\n",
    "#         for lag in range(min_lag, max_lag):\n",
    "#             if t - lag >= 0:\n",
    "#                 score = onset_signal[t] + dp[t - lag]\n",
    "#                 if score > max_score:\n",
    "#                     max_score = score\n",
    "#                     best_lag = lag\n",
    "#         dp[t] = max_score\n",
    "#         backtrack[t] = best_lag\n",
    "    \n",
    "#     # Backtrack to find beat positions\n",
    "#     beat_positions = []\n",
    "#     t = np.argmax(dp)\n",
    "#     while t >= min_lag:\n",
    "#         beat_positions.append(t)\n",
    "#         t -= backtrack[t]\n",
    "    \n",
    "#     beat_positions = beat_positions[::-1]  # reverse to get the correct order\n",
    "#     return np.array(beat_positions) * utils.HOP_LENGTH / utils.SAMPLING_RATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "210c3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_beat_tracking(spec, sample_rate, tempo_estimations):    \n",
    "#     num_frames = spec.shape[-1]\n",
    "#     duration = num_frames * utils.HOP_LENGTH / sample_rate\n",
    "\n",
    "#     onset_signal = raw_onset_signal(model, spec)\n",
    "\n",
    "#     # Calculate the average tempo if multiple tempo estimations are provided\n",
    "#     if isinstance(tempo_estimations, (list, np.ndarray)):\n",
    "#         tempo = np.mean(tempo_estimations)\n",
    "#     else:\n",
    "#         tempo = tempo_estimations\n",
    "\n",
    "#     taos = autocorrelate_tao(onset_signal)\n",
    "#     peaks = find_peaks(taos)[0]\n",
    "\n",
    "#     # Convert peak indices to time\n",
    "#     peak_times = librosa.frames_to_time(peaks, sr=sample_rate, hop_length=utils.HOP_LENGTH)\n",
    "        \n",
    "#     # Initialize beat times list\n",
    "#     beat_times = []\n",
    "\n",
    "#     beat_interval = 60.0 / tempo\n",
    "\n",
    "#     # Align detected peaks with expected beat intervals\n",
    "#     for peak_time in peak_times:\n",
    "#         current_beat_time = peak_time\n",
    "#         while current_beat_time < duration:\n",
    "#             beat_times.append(current_beat_time)\n",
    "#             current_beat_time += beat_interval\n",
    "    \n",
    "#     return np.array(beat_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb3c6c9846eac955",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T15:11:28.450118Z",
     "start_time": "2024-05-30T15:11:28.443393Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the paths and then split them into train and test set (validation set in our case for now).\n",
    "wav_files_paths_train, beat_files_paths_train, _, _ = utils.load_dataset_paths(train_dataset_path, is_train_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fecd855076c30ddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T15:11:36.747587Z",
     "start_time": "2024-05-30T15:11:35.184867Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:04<00:00, 26.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare train data\n",
    "features_train, sample_rates_train = utils.preprocess_audio(wav_files_paths_train)\n",
    "\n",
    "# tempo_train = utils.load_tempo_annotations_from_files(y_train_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "373851ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "onsets = [raw_onset_signal(model, x, mean, std) for x in features_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b97ca01d6321c9b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-30T15:11:56.497086Z",
     "start_time": "2024-05-30T15:11:45.187766Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempos = [get_tempo(model, x) for x in features_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6d41a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import librosa\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# class BeatTrackingDataset(Dataset):\n",
    "#     def __init__(self, directory):\n",
    "#         self.directory = directory\n",
    "#         self.file_pairs = self._load_file_pairs()\n",
    "#         self.data = []\n",
    "#         self.labels = []\n",
    "#         self._prepare_dataset()\n",
    "    \n",
    "#     def _load_file_pairs(self):\n",
    "#         file_pairs = []\n",
    "#         for file in os.listdir(self.directory):\n",
    "#             if file.endswith(\".wav\"):\n",
    "#                 wav_file = os.path.join(self.directory, file)\n",
    "#                 beat_file = os.path.join(self.directory, file.replace(\".wav\", \".beats.gt\"))\n",
    "#                 if os.path.exists(beat_file):\n",
    "#                     file_pairs.append((wav_file, beat_file))\n",
    "#         return file_pairs\n",
    "\n",
    "#     def _load_annotations(self, annotations_file):\n",
    "#         with open(annotations_file, 'r') as f:\n",
    "#             annotations = [float(line.strip().split(\"\\t\")[0]) for line in f]\n",
    "#         return annotations\n",
    "\n",
    "#     def _prepare_dataset(self):\n",
    "#         for wav_file, beat_file in self.file_pairs:\n",
    "#             y, sr = librosa.load(wav_file, sr=None)\n",
    "#             mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "#             onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "#             beat_times = self._load_annotations(beat_file)\n",
    "#             beat_frames = librosa.time_to_frames(beat_times, sr=sr)\n",
    "#             labels = np.zeros(len(onset_env))\n",
    "#             labels[beat_frames] = 1  # Mark the beats\n",
    "#             self.data.append(np.vstack([mfcc, onset_env]))\n",
    "#             self.labels.append(labels)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e966da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_dataloader(dir, batch_size=1, shuffle=True):\n",
    "#     dataset = BeatTrackingDataset(dir)\n",
    "#     return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b085388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class Chomp1d(nn.Module):\n",
    "#     def __init__(self, chomp_size):\n",
    "#         super(Chomp1d, self).__init__()\n",
    "#         self.chomp_size = chomp_size\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return x[:, :, :-self.chomp_size]\n",
    "\n",
    "# class TemporalBlock(nn.Module):\n",
    "#     def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "#         super(TemporalBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "#                                stride=stride, padding=padding, dilation=dilation)\n",
    "#         self.chomp1 = Chomp1d(padding)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "#         self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "#                                stride=stride, padding=padding, dilation=dilation)\n",
    "#         self.chomp2 = Chomp1d(padding)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "#         self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "#                                  self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "#         self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.init_weights()\n",
    "\n",
    "#     def init_weights(self):\n",
    "#         self.conv1.weight.data.normal_(0, 0.01)\n",
    "#         self.conv2.weight.data.normal_(0, 0.01)\n",
    "#         if self.downsample is not None:\n",
    "#             self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.net(x)\n",
    "#         res = x if self.downsample is None else self.downsample(x)\n",
    "#         return self.relu(out + res)\n",
    "\n",
    "# class TemporalConvNet(nn.Module):\n",
    "#     def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "#         super(TemporalConvNet, self).__init__()\n",
    "#         layers = []\n",
    "#         num_levels = len(num_channels)\n",
    "#         for i in range(num_levels):\n",
    "#             dilation_size = 2 ** i\n",
    "#             in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "#             out_channels = num_channels[i]\n",
    "#             layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "#                                      padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "#         self.network = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d889ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BeatTrackingModel(nn.Module):\n",
    "#     def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "#         super(BeatTrackingModel, self).__init__()\n",
    "#         self.tcn = TemporalConvNet(num_inputs, num_channels, kernel_size, dropout)\n",
    "#         self.linear = nn.Linear(num_channels[-1], 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         y1 = self.tcn(x)\n",
    "#         o = self.linear(y1.transpose(1, 2))\n",
    "#         return torch.sigmoid(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47635d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "\n",
    "# def train_model(model, dataloader, num_epochs=50, lr=0.001):\n",
    "#     criterion = nn.BCELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         for inputs, labels in dataloader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             outputs = outputs.squeeze(-1)\n",
    "#             print(labels)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "        \n",
    "#         print(f\"Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}\")\n",
    "\n",
    "# # Example usage:\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# model = BeatTrackingModel(num_inputs=14, num_channels=[25, 25, 25], kernel_size=2, dropout=0.2).to(device)\n",
    "# dataloader = create_dataloader(train_dataset_path)\n",
    "# train_model(model, dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a806f088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# def predict_beats(model, file_path):\n",
    "#     y, sr = librosa.load(file_path, sr=None)\n",
    "#     mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "#     onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "#     data = np.vstack([mfcc, onset_env])\n",
    "#     data = torch.tensor(data, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         output = model(data)\n",
    "#         output = output.squeeze().cpu().numpy()\n",
    "    \n",
    "#     predicted_beats = np.where(output > 0.5)[0]\n",
    "#     beat_times = librosa.frames_to_time(predicted_beats, sr=sr)\n",
    "#     return beat_times\n",
    "\n",
    "# # Example usage:\n",
    "# beat_times = predict_beats(model, \"data/test/test02.wav\")\n",
    "# print(beat_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c64c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import librosa\n",
    "# import math\n",
    "\n",
    "\n",
    "# class BeatAgent:\n",
    "#     def __init__(self, start_time, tempo, onset_times, sr, hop_length, inner_window, outer_window, score=0):\n",
    "#         self.start_time = start_time\n",
    "#         self.current_time = start_time\n",
    "#         self.tempo = tempo\n",
    "#         self.onset_times = onset_times\n",
    "#         self.sr = sr\n",
    "#         self.hop_length = hop_length\n",
    "#         self.beat_interval = 60.0 / tempo\n",
    "#         self.beat_times = [start_time]\n",
    "#         self.score = score\n",
    "#         self.inner_window = inner_window\n",
    "#         self.outer_window = outer_window\n",
    "#         self.prev_event = None\n",
    "\n",
    "#     def update(self, duration):\n",
    "#         while self.current_time < duration:\n",
    "#             self.prev_event = self.current_time\n",
    "#             # next_value = self.current_time + self.beat_interval\n",
    "#             # nearest_event = self.__find_nearest(self.onset_times, next_value)\n",
    "#             # print(type(self.onset_times))\n",
    "#             # nearest_event = min(self.onset_times, key=lambda x: abs(x - next_value))\n",
    "    \n",
    "#             # if abs(nearest_event - next_value) <= self.inner_window and self.prev_event is not None and self.prev_event < nearest_event:\n",
    "#             #     self.current_time = nearest_event\n",
    "#             # else:\n",
    "#             self.current_time += self.beat_interval\n",
    "\n",
    "#             self.beat_times.append(self.current_time)\n",
    "    \n",
    "#     def __find_nearest(self, array, value):\n",
    "#         idx = np.searchsorted(array, value, side=\"left\")\n",
    "#         if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "#             return array[idx-1]\n",
    "#         else:\n",
    "#             return array[idx]\n",
    "\n",
    "#     def calculate_score(self):\n",
    "#         beat_intervals = np.diff(self.beat_times)\n",
    "#         mean_interval = np.mean(beat_intervals)\n",
    "#         self.score = np.sum((beat_intervals - mean_interval) ** 2)\n",
    "    \n",
    "#     def process_event(self, event_time):\n",
    "#         time_diff = abs(event_time - self.current_time)\n",
    "\n",
    "#         if time_diff <= self.inner_window and self.prev_event is not None and event_time > self.prev_event:\n",
    "#             self.prev_event = self.current_time\n",
    "#             self.current_time = event_time\n",
    "#             self.beat_times.append(event_time)\n",
    "#             return True\n",
    "#         if time_diff <= self.outer_window:\n",
    "#             return False\n",
    "#         return False\n",
    "    \n",
    "#     def __str__(self):\n",
    "#         return \"Start time: \" + str(self.start_time) + \", Tempo:\" + str(self.tempo)\n",
    "\n",
    "# def multiple_agent_beat_tracking(wav_file, onsets, tempo_estimations):\n",
    "#     y, sr = librosa.load(wav_file)\n",
    "#     duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "#     agents = []\n",
    "#     for tempo in tempo_estimations:\n",
    "#         for onset_time in onsets:\n",
    "#             agents.append(BeatAgent(start_time=onset_time, tempo=tempo, onset_times=onsets, sr=sr, hop_length=utils.HOP_LENGTH, inner_window=0.05, outer_window=0.1))\n",
    "    \n",
    "#     print(len(agents))\n",
    "\n",
    "#     for event_time in onsets:\n",
    "#         new_agents = []\n",
    "#         for agent in agents:\n",
    "#             if not agent.process_event(event_time):\n",
    "#                 cloned_agent = BeatAgent(agent.current_time, agent.tempo, agent.onset_times, agent.sr, agent.hop_length, agent.inner_window, agent.outer_window, score=agent.score)\n",
    "#                 if cloned_agent.process_event(event_time):\n",
    "#                     new_agents.append(cloned_agent)\n",
    "#         agents.extend(new_agents)\n",
    "\n",
    "#     for agent in agents:\n",
    "#         agent.update(duration)\n",
    "#         agent.calculate_score()\n",
    "\n",
    "#     best_agent = max(agents, key=lambda agent: agent.score)\n",
    "#     print(best_agent)\n",
    "\n",
    "#     return np.array(best_agent.beat_times)\n",
    "\n",
    "# wav_file = \"data/train/Media-105810(5.0-15.0).wav\"\n",
    "# # wav_file = \"data/test/test48.wav\"\n",
    "# ft_, sr_ = utils.preprocess_audio([wav_file])\n",
    "# ft_ = ft_[0]\n",
    "# sr_ = sr_[0]\n",
    "# # onset_ = raw_onset_signal(model, ft_, mean, std)\n",
    "# # peaks, _ = scipy.signal.find_peaks(onset_, height=np.max(onset_) * 0.5)\n",
    "\n",
    "# # onset_times = librosa.frames_to_time(peaks, sr=utils.SAMPLING_RATE, hop_length=utils.HOP_LENGTH)\n",
    "# f=open(\"data/train/Media-105810(5.0-15.0).onsets.gt\", \"r\")\n",
    "# lines=f.readlines()\n",
    "# true_onsets=[]\n",
    "# for x in lines:\n",
    "#     true_onsets.append(float(x.split('\\t')[0]))\n",
    "# f.close()\n",
    "\n",
    "# tempo_ = get_tempo(model, ft_)\n",
    "# beats_ = multiple_agent_beat_tracking(wav_file, true_onsets, tempo_)\n",
    "# beats_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16d395e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 39.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.07764172,  0.36208617,  0.65088435,  0.98776318,  1.33297052,\n",
       "        1.66983359,  2.01      ,  2.29369615,  2.63065354,  2.95764172,\n",
       "        3.29461798,  3.64      ,  3.97696035,  4.34068027,  4.67758999,\n",
       "        5.00244898,  5.3393815 ,  5.67219955,  5.96      ,  6.29703331,\n",
       "        6.6430839 ,  6.93      ,  7.26711111,  7.58131519,  7.870839  ,\n",
       "        8.16979592,  8.45786848,  8.75      ,  9.11      ,  9.44745399,\n",
       "        9.78213152, 10.11959078, 10.46      , 10.74      , 11.07756274,\n",
       "       11.40027211, 11.68      , 12.01770089, 12.34358277, 12.61424036,\n",
       "       12.88707483, 13.17442177, 13.51249281, 13.85      , 14.10104308,\n",
       "       14.41160998, 14.74990072, 15.09      , 15.42828729, 15.69      ,\n",
       "       16.03      , 16.36843042, 16.72      , 17.07      , 17.40838321,\n",
       "       17.72843537, 18.06685357, 18.39      , 18.65      , 18.94      ,\n",
       "       19.27869007, 19.60780045, 19.94650883, 20.24562358, 20.58440769,\n",
       "       20.92408163, 21.23      , 21.56884528, 21.9       , 22.19      ,\n",
       "       22.52895353, 22.83319728, 23.14      , 23.47908173, 23.81      ,\n",
       "       24.14909737, 24.46730159, 24.76      , 25.09922646, 25.42730159,\n",
       "       25.83      , 26.16      , 26.50848072, 26.83428571, 27.09      ,\n",
       "       27.33      , 27.63900227, 27.9       , 28.23971166, 28.58      ,\n",
       "       28.87      , 29.20980619, 29.54      , 29.82965986])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BeatAgent:\n",
    "    def __init__(self, id, start_time, tempo_hypothesis, initial_tempo, inner_window, outer_window, parent_agent=None):\n",
    "        self.id = str(id)\n",
    "        self.start_time = start_time\n",
    "        self.initial_tempo = initial_tempo\n",
    "        self.tempo_hypothesis = tempo_hypothesis\n",
    "        self.beat_interval = 60.0 / tempo_hypothesis\n",
    "        self.next_prediction = start_time + self.beat_interval\n",
    "        # self.current_time = start_time\n",
    "        self.accepted_events = [start_time]\n",
    "        self.inner_window = inner_window\n",
    "        self.outer_window = outer_window\n",
    "        self.moved = False\n",
    "        self.score = 0\n",
    "        # self.source = [\"init\"]\n",
    "    \n",
    "        # this means it is a sub agebt that is created from an outer_window prediction\n",
    "        if parent_agent is not None:\n",
    "            self.score = parent_agent.score\n",
    "            self.moved = True\n",
    "            self.next_prediction = parent_agent.next_prediction + self.beat_interval\n",
    "            self.accepted_events = parent_agent.accepted_events.copy()\n",
    "            # self.source = parent_agent.source.copy()\n",
    "            self.accepted_events.append(parent_agent.next_prediction)\n",
    "            # self.source.append(\"new agent\")\n",
    "    \n",
    "    def process_event(self, event):\n",
    "        event_diff = abs(event - self.next_prediction)\n",
    "       \n",
    "        if event == self.next_prediction: # the event predicted\n",
    "            # print(\"Exact\\n\")\n",
    "            self.accepted_events.append(event)\n",
    "            # self.source.append(\"exact\")\n",
    "            self.score += self.outer_window\n",
    "            # self.current_time = event\n",
    "            self.next_prediction = event + self.beat_interval\n",
    "            self.moved = True\n",
    "            return None\n",
    "        elif event_diff <= self.inner_window: # the event is inside the inner window\n",
    "            # print(\"Inner Window\\n\")\n",
    "            self.accepted_events.append(event)\n",
    "            # self.source.append(\"inner\")\n",
    "            self.__update_tempo_hypothesis(event)\n",
    "            self.score += (self.outer_window - event_diff)\n",
    "            # self.current_time = event\n",
    "            self.next_prediction = event + self.beat_interval\n",
    "            self.moved = True\n",
    "            return None\n",
    "        elif event_diff <= self.outer_window: # the event is inside the outer window\n",
    "            # print(\"Outer Window\\n\")\n",
    "            new_agent = BeatAgent(self.id + \"a\", self.start_time, self. tempo_hypothesis, \n",
    "                                  self.initial_tempo, self.inner_window, self.outer_window, self)\n",
    "\n",
    "            self.accepted_events.append(event)\n",
    "            # self.source.append(\"outer\")\n",
    "            self.__update_tempo_hypothesis(event)\n",
    "            self.score += (self.outer_window - event_diff)\n",
    "            # self.current_time = event\n",
    "            self.next_prediction = event + self.beat_interval\n",
    "            self.moved = True\n",
    "            return new_agent # return a new agent\n",
    "        elif event > self.next_prediction + self.outer_window:\n",
    "            # print(\"Interpolated Beat\\n\")\n",
    "            # interpolated beat, grants no score\n",
    "            self.accepted_events.append(event)\n",
    "            # self.current_time = event\n",
    "            self.next_prediction = event + self.beat_interval\n",
    "            # self.source.append(\"interpolate\")\n",
    "            self.moved = True\n",
    "            return None\n",
    "        \n",
    "        # print(\"Ignore\\n\")\n",
    "    \n",
    "    def __update_tempo_hypothesis(self, event):\n",
    "        self.tempo_hypothesis = self.tempo_hypothesis + (event - self.next_prediction)\n",
    "        self.beat_interval = 60.0 / self.tempo_hypothesis\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Start time: \" + str(self.start_time) + \", Tempo:\" + str(self.initial_tempo)\n",
    "\n",
    "def prune_similiar_agents(agents): # \n",
    "    agents_tempo_map = {}\n",
    "    agents_to_keep = []\n",
    "\n",
    "    for agent in agents:\n",
    "        th = round(agent.tempo_hypothesis, 3)\n",
    "        if not agent.moved:\n",
    "            agents_to_keep.append(agent)\n",
    "        elif th not in agents_tempo_map:\n",
    "            agents_tempo_map[th] = agent\n",
    "        elif agent.score > agents_tempo_map[th].score:\n",
    "                agents_tempo_map[th] = agent\n",
    "\n",
    "    for th in agents_tempo_map:\n",
    "        agents_to_keep.append(agents_tempo_map[th])\n",
    "    \n",
    "    return agents_to_keep\n",
    "\n",
    "def multiple_agent_beat_tracking(onsets, tempo_estimations):\n",
    "    id = 0\n",
    "    agents = []\n",
    "    for tempo in tempo_estimations:\n",
    "        for idx in range(0, min(10, len(onsets))):\n",
    "            agents.append(BeatAgent(id, onsets[idx], tempo, tempo, 0.05, 0.1))\n",
    "            id += 1\n",
    "    \n",
    "    # agents = [BeatAgent(onsets[0], tempo_estimations[1], tempo_estimations[1], 0.055, 0.1)]\n",
    "    for event_time in onsets:\n",
    "        next_agents = []\n",
    "        for agent in agents:\n",
    "            if agent.start_time < event_time:\n",
    "                new_agent = agent.process_event(event_time)\n",
    "                if new_agent is not None:\n",
    "                    next_agents.append(new_agent)\n",
    "        \n",
    "        \n",
    "        \n",
    "        agents += next_agents\n",
    "        agents = prune_similiar_agents(agents)\n",
    "\n",
    "    best_agent: BeatAgent = max(agents, key=lambda agent: agent.score)\n",
    "    # print(best_agent)\n",
    "    # print(best_agent.id)\n",
    "    # print(best_agent.source)\n",
    "\n",
    "    return np.array(best_agent.accepted_events)\n",
    "\n",
    "wav_file = \"data/train/Media-105810(5.0-15.0).wav\"\n",
    "# wav_file = \"data/test/test48.wav\"\n",
    "ft_, sr_ = utils.preprocess_audio([wav_file])\n",
    "ft_ = ft_[0]\n",
    "# sr_ = sr_[0]\n",
    "# onset_ = raw_onset_signal(model, ft_, mean, std)\n",
    "\n",
    "# import scipy\n",
    "# peaks, _ = scipy.signal.find_peaks(onset_, height=np.max(onset_) * 0.5)\n",
    "\n",
    "# onset_times = librosa.frames_to_time(peaks, sr=utils.SAMPLING_RATE, hop_length=utils.HOP_LENGTH)\n",
    "\n",
    "###### used the ground truth onsets in order to not blame outside factors\n",
    "f=open(\"data/train/Media-105810(5.0-15.0).onsets.gt\", \"r\")\n",
    "f=open(\"data/train/train20.onsets.gt\", \"r\")\n",
    "lines=f.readlines()\n",
    "true_onsets=[]\n",
    "for x in lines:\n",
    "    true_onsets.append(float(x.split('\\t')[0]))\n",
    "f.close()\n",
    "######\n",
    "\n",
    "tempo_ = get_tempo(model, ft_)\n",
    "beats_ = multiple_agent_beat_tracking(true_onsets, tempo_)\n",
    "beats_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4368e2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:04<00:00, 28.72it/s]\n"
     ]
    }
   ],
   "source": [
    "features_train, sample_rates_train = utils.preprocess_audio(wav_files_paths_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a48012",
   "metadata": {},
   "outputs": [],
   "source": [
    "beatsT = {}\n",
    "tempos = {}\n",
    "for _, (ft, wav_file) in enumerate(zip(features_train, wav_files_paths_train)):\n",
    "    filename = wav_file.split('/')[-1].replace('.wav', '')\n",
    "    # on = get_onset_preds(model, ft, mean, std)\n",
    "    f=open(wav_file.replace(\".wav\", \".onsets.gt\"), \"r\")\n",
    "    lines=f.readlines()\n",
    "    true_onsets=[]\n",
    "    for x in lines:\n",
    "        true_onsets.append(float(x))\n",
    "    f.close()\n",
    "    temp = get_tempo(model, ft)\n",
    "    beatsT[filename] = multiple_agent_beat_tracking(true_onsets, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac473dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {}\n",
    "if \"./data/train/ff123_bloodline.wav\" in wav_files_paths_train:\n",
    "    wav_files_paths_train.remove(\"./data/train/ff123_bloodline.wav\")\n",
    "\n",
    "for filename in wav_files_paths_train:\n",
    "    filename = filename.split('/')[-1].replace('.wav', '')\n",
    "    pred[filename] = {'beats': beatsT[filename]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "649d2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = {}\n",
    "if \"./data/train/ff123_bloodline.wav\" in wav_files_paths_train:\n",
    "    wav_files_paths_train.remove(\"./data/train/ff123_bloodline.wav\")\n",
    "\n",
    "for filename in wav_files_paths_train:\n",
    "    wav_f = filename.split('/')[-1].replace('.wav', '')\n",
    "    beat_filename = filename.replace(\".wav\", \".beats.gt\")\n",
    "    f=open(beat_filename, \"r\")\n",
    "    lines=f.readlines()\n",
    "    result=[]\n",
    "    for x in lines:\n",
    "        result.append(float(x.split('\\t')[0]))\n",
    "    f.close()\n",
    "    target[wav_f] = {'beats': result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "894826ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4899458469356703\n"
     ]
    }
   ],
   "source": [
    "def evaluate_loop(submission, target):\n",
    "    sum_f = 0.\n",
    "    for target_key, target_value in target.items():\n",
    "        if target_key in submission:\n",
    "            reference = target_value['beats']\n",
    "            estimated = submission[target_key]['beats']\n",
    "            f = mir_eval.beat.f_measure(\n",
    "                np.array(reference),\n",
    "                np.array(estimated),\n",
    "                f_measure_threshold=0.07  # 70 [ms]\n",
    "            )\n",
    "        else:\n",
    "            f = 0.\n",
    "\n",
    "        sum_f += f\n",
    "    return sum_f / len(target)\n",
    "\n",
    "\n",
    "print(evaluate_loop(pred, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b80e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path = 'beats.json'\n",
    "\n",
    "# Open the file in write mode and save the dictionary\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(pred, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
