{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T21:41:39.177427Z",
     "start_time": "2024-05-18T21:41:39.163651Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utility as utils\n",
    "import importlib\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import mir_eval\n",
    "import glob\n",
    "from os import path\n",
    "import data\n",
    "import models\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(data)\n",
    "\n",
    "train_dataset_path = './data/onset/train_extra_onsets'\n",
    "test_dataset_path = './data/onset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "wav_files_paths, _, onset_files_paths, _ = utils.load_dataset_paths(train_dataset_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T20:50:31.569218Z",
     "start_time": "2024-05-18T20:50:31.565864Z"
    }
   },
   "id": "3aff0e05078388d4"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    }
   ],
   "source": [
    "X_files_train, X_files_test, y_files_train, y_files_test = train_test_split(wav_files_paths, onset_files_paths, test_size=0.2, random_state=42)\n",
    "print(len(X_files_train), len(X_files_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T20:50:31.710949Z",
     "start_time": "2024-05-18T20:50:31.707443Z"
    }
   },
   "id": "d96ba485978e822a"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.96it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, sample_rates = utils.preprocess_audio(X_files_train)\n",
    "onsets_train = utils.load_onsets(y_files_train)\n",
    "y_train = [utils.make_target(onsets_train[i], X_train[i].shape[-1], sample_rates[i]) for i in range(len(onsets_train))]\n",
    "\n",
    "X_train_tensors = [torch.tensor(spec, dtype=torch.float32) for spec in X_train]\n",
    "y_train_tensors = [torch.tensor(target, dtype=torch.float32) for target in y_train]\n",
    "X_train_tensors = torch.stack(X_train_tensors)\n",
    "y_train_tensors = torch.stack(y_train_tensors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T21:38:04.574874Z",
     "start_time": "2024-05-18T21:38:04.471705Z"
    }
   },
   "id": "fb6fa1828a798dd9"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 60.92it/s]\n",
      "/var/folders/99/617f3z715_g8nc26tll89ddc0000gn/T/ipykernel_13157/494878452.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_tensors = [torch.tensor(spec, dtype=torch.float32) for spec in X_test]\n"
     ]
    }
   ],
   "source": [
    "X_test, sample_rates_test = data.preprocess_audio(X_files_test)\n",
    "onsets_test = [data.load_onsets(path) for path in y_files_test]\n",
    "\n",
    "X_test_tensors = [torch.tensor(spec, dtype=torch.float32) for spec in X_test]\n",
    "X_test_tensors = torch.stack(X_test_tensors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T21:38:44.295130Z",
     "start_time": "2024-05-18T21:38:44.270852Z"
    }
   },
   "id": "38e53643ce1d1c0f"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AudioOnsetDataset(th.utils.data.Dataset):\n",
    "    def __init__(self, spectograms, sample_rates, targets, sample_onsets):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        for X, sample_rate, y, onsets in zip(spectograms, sample_rates, targets, sample_onsets):\n",
    "            X_frames, y_frames = utils.create_audio_onset_dataset(X, y, onsets, sample_rate)\n",
    "\n",
    "            self.X += X_frames\n",
    "            self.y += y_frames\n",
    "\n",
    "        tmp = th.cat(self.X)\n",
    "        self.mean = th.mean(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "        self.std = th.std(tmp, dim=(0, 2)).unsqueeze(1)\n",
    "        del tmp\n",
    "\n",
    "        self.X = [(x - self.mean)/self.std for x in self.X]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T21:38:55.016978Z",
     "start_time": "2024-05-18T21:38:55.014631Z"
    }
   },
   "id": "57c6e8c7457d4d29"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(c, c, 3, padding='same'),\n",
    "            nn.BatchNorm2d(c),\n",
    "            nn.ReLU(c),\n",
    "            nn.Conv2d(c, c, 3, padding='same'),\n",
    "            nn.BatchNorm2d(c)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(x + self.block(x))\n",
    "\n",
    "class Resi(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Sequential(\n",
    "            nn.Conv2d(input_dim, 16, (3, 7), padding=(0, 3)), # 16xLx78\n",
    "            nn.ReLU(),\n",
    "            ResBlock(16), # 16xLx78\n",
    "            nn.MaxPool2d((3, 1)), # 16xLx26\n",
    "            nn.Dropout2d(0.4),\n",
    "            nn.Conv2d(16, 32, (3, 3), padding=(0, 1)), # 32xLx24\n",
    "            nn.ReLU(),\n",
    "            ResBlock(32), # 32xLx24\n",
    "            nn.MaxPool2d((3, 1)), # 32xLx8\n",
    "            nn.Dropout2d(0.4),\n",
    "            nn.Conv2d(32, 64, (3, 3), padding=(0, 1)), # 64xLx6\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool2d((1, None)), # 64xLx1\n",
    "            nn.Dropout2d(0.4),\n",
    "            nn.Conv2d(64, 1, 1) # 1xLx1\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = self.embed(X)\n",
    "        out = th.flatten(out, start_dim=1)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T21:38:55.495219Z",
     "start_time": "2024-05-18T21:38:55.493549Z"
    }
   },
   "id": "a465a737249326e7"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "dataset = data.AudioOnsetDataset(X_train_tensors, sample_rates, y_train_tensors, onsets_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T21:40:25.906127Z",
     "start_time": "2024-05-18T21:40:25.881725Z"
    }
   },
   "id": "281b19f670a50108"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "device = 'cuda' if th.cuda.is_available() else 'cpu'\n",
    "lr = 3e-4\n",
    "\n",
    "train_dataloader = DataLoader(dataset, shuffle=True, batch_size=256)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T21:41:42.257420Z",
     "start_time": "2024-05-18T21:41:42.247733Z"
    }
   },
   "id": "1ed10e78f680e383"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = models.Resi(3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "pos_weight = th.Tensor([14.]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "data_mean, data_std = dataset.mean.to(device), dataset.std.to(device)\n",
    "\n",
    "best_mean = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    print(f'epoch {epoch + 1}')\n",
    "\n",
    "    for batch_idx, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # fuzzy weight mask\n",
    "        mask = th.ones_like(y)\n",
    "        mask[y == 0.25] = 0.25\n",
    "        y[y == 0.25] = 1.\n",
    "\n",
    "        out = model(X)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y, weight=mask, pos_weight=pos_weight)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'loss: {loss.item()}')\n",
    "\n",
    "    model.eval()\n",
    "    f_scores_train = onsets.evaluate_onsets(model, X_train, onsets_train, data_mean, data_std)\n",
    "    f_scores_test = onsets.evaluate_onsets(model, X_test, onsets_test, data_mean, data_std)\n",
    "    f_mean_test = np.mean(f_scores_test)\n",
    "    print(f'F-scores: TRAIN {np.mean(f_scores_train)} | TEST {np.mean(f_mean_test)}')\n",
    "\n",
    "    if f_mean_test > best_mean:\n",
    "        best_mean = f_mean_test\n",
    "        th.save(model.state_dict(), 'resi.pt')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef2d718e953e8eb0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
