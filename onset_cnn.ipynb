{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-12T21:55:04.792120Z",
     "start_time": "2024-05-12T21:55:04.783723Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import utility as utils\n",
    "import importlib\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mir_eval\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "importlib.reload(utils)\n",
    "\n",
    "train_dataset = './data/onset/train'\n",
    "test_dataset = './data/onset/test'"
   ],
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T21:34:55.081443Z",
     "start_time": "2024-05-12T21:34:55.078072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_loop(submission, target):\n",
    "    f, _, _ = mir_eval.onset.f_measure(\n",
    "        np.array(target),\n",
    "        np.array(submission),\n",
    "        window=0.05  # 50 [ms]\n",
    "    )\n",
    "    return f"
   ],
   "id": "175f1e870325f35f",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T21:34:55.436066Z",
     "start_time": "2024-05-12T21:34:55.382417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = utils.get_audio_and_onsets_in_dataframe(train_dataset)"
   ],
   "id": "4f3ff9f634db5a71",
   "outputs": [],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T21:34:56.087833Z",
     "start_time": "2024-05-12T21:34:56.080779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import numpy as np\n",
    "# import librosa\n",
    "# \n",
    "# def preprocess_audio_to_cnn_input(audio_path, sr=utils.SAMPLING_RATE, n_mels=80, fmin=27.5, fmax=16000):\n",
    "#     # Loading & defining the stuff\n",
    "#     hop_length = int(sr * 0.01)\n",
    "#     context_frames = 7\n",
    "#     y, sr = librosa.load(audio_path, sr=sr)\n",
    "# \n",
    "#     # Prepare spectrograms\n",
    "#     melspecs = []\n",
    "#     for window_size in [int(sr * 0.023), int(sr * 0.046), int(sr * 0.093)]:\n",
    "#         melspec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=window_size, hop_length=hop_length,\n",
    "#                                                  n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
    "#         melspec = librosa.power_to_db(melspec)\n",
    "#         melspecs.append(melspec)\n",
    "# \n",
    "#     # Padding part in case that one of the spectograms wouldn't allign correctly.\n",
    "#     max_length = max(mel.shape[1] for mel in melspecs)\n",
    "#     melspecs = [np.pad(mel, ((0, 0), (0, max_length - mel.shape[1])), mode='constant') for mel in melspecs]\n",
    "# \n",
    "#     melspecs = np.stack(melspecs, axis=-1)  # Stacking along the new axis to treat them as channels\n",
    "#     mean = np.mean(melspecs, axis=(0, 2), keepdims=True)\n",
    "#     std = np.std(melspecs, axis=(0, 2), keepdims=True)\n",
    "#     melspecs = (melspecs - mean) / std\n",
    "# \n",
    "#     # Combine and prepare the context window data for each time frame\n",
    "#     num_frames = melspecs.shape[1]  # Number of frames should now be consistent\n",
    "#     cnn_inputs = []\n",
    "#     for t in range(context_frames, num_frames - context_frames):\n",
    "#         # Extract the context window for all channels\n",
    "#         context_window = melspecs[:, t-context_frames:t+context_frames+1, :]\n",
    "#         cnn_inputs.append(context_window)\n",
    "#     cnn_inputs = np.array(cnn_inputs)\n",
    "#     cnn_inputs = cnn_inputs.reshape(cnn_inputs.shape[0], 15, 80, 3)\n",
    "# \n",
    "#     return cnn_inputs\n",
    "# \n",
    "# def onsets_to_frames(onset_times, sr=utils.SAMPLING_RATE):\n",
    "#     # Calculate frame duration in seconds\n",
    "#     hop_length = int(sr * 0.01)\n",
    "#     frame_duration = hop_length / sr\n",
    "#     # Calculate frame indices for each onset time\n",
    "#     frame_indices = [int(time / frame_duration) for time in onset_times]\n",
    "# \n",
    "#     # Assume maximum frame index to create the binary array\n",
    "#     if frame_indices:\n",
    "#         max_index = max(frame_indices)\n",
    "#         onsets_binary = np.zeros(max_index + 1, dtype=int)  # +1 because indexing starts at 0\n",
    "#         onsets_binary[frame_indices] = 1\n",
    "#     else:\n",
    "#         onsets_binary = np.array([])\n",
    "#     return np.array(onsets_binary)\n",
    "# \n",
    "# def frames_to_onset(onset_binary, sr=utils.SAMPLING_RATE):\n",
    "#     hop_length = int(sr * 0.01)  # Calculate hop length from sampling rate\n",
    "#     frame_duration = hop_length / sr  # Calculate the duration of each frame in seconds\n",
    "# \n",
    "#     # Find indices where there is an onset\n",
    "#     onset_indices = np.where(onset_binary == 1)[0]\n",
    "# \n",
    "#     # Convert frame indices to times\n",
    "#     onset_times = onset_indices * frame_duration\n",
    "# \n",
    "#     return onset_times.tolist()  # Convert to list for convenience\n",
    "# \n",
    "# def prepare_data(audio_path, onset_times, sr=utils.SAMPLING_RATE, n_mels=80, fmin=27.5, fmax=16000):\n",
    "#     # Generate Mel spectrograms\n",
    "#     melspecs = preprocess_audio(audio_path, sr, n_mels, fmin, fmax)\n",
    "# \n",
    "#     # Convert onset times to frame indices\n",
    "#     hop_length = int(sr * 0.01)\n",
    "#     frame_indices = [int(time * sr / hop_length) for time in onset_times]\n",
    "#     max_index = max(frame_indices, default=0)\n",
    "# \n",
    "#     # Prepare labels for each frame in the spectrogram\n",
    "#     labels = np.zeros((max_index + 1,), dtype=int)\n",
    "#     for index in frame_indices:\n",
    "#         labels[index] = 1\n",
    "# \n",
    "#     return melspecs, labels\n",
    "# \n",
    "# def process_data(audio_paths, onset_times_list, sr=utils.SAMPLING_RATE, n_mels=80, fmin=27.5, fmax=16000):\n",
    "#     all_features = []\n",
    "#     all_labels = []\n",
    "# \n",
    "#     # Iterate through the lists with a tqdm progress bar\n",
    "#     for audio_path, onset_times in tqdm(zip(audio_paths, onset_times_list), total=len(audio_paths), desc=\"Processing audio files\"):\n",
    "#         # Prepare data from this file\n",
    "#         features, labels = prepare_data(audio_path, onset_times, sr, n_mels, fmin, fmax)\n",
    "#         print(np.array(features).shape)\n",
    "#         # Aggregate the data\n",
    "#         all_features.append(features)\n",
    "#         all_labels.append(labels)\n",
    "# \n",
    "#     # Concatenate all data into arrays\n",
    "#     all_features = np.concatenate(all_features, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "# \n",
    "#     return all_features, all_labels"
   ],
   "id": "86e5da29354e7ab7",
   "outputs": [],
   "execution_count": 149
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "def frames_to_onset(onset_binary, sr=utils.SAMPLING_RATE):\n",
    "    hop_length = int(sr * 0.01)  # Calculate hop length from sampling rate\n",
    "    frame_duration = hop_length / sr  # Calculate the duration of each frame in seconds\n",
    "    onset_indices = np.where(onset_binary == 1)[0]\n",
    "    onset_times = onset_indices * frame_duration\n",
    "\n",
    "    return onset_times.tolist()\n",
    "\n",
    "def preprocess_test_data(audio_path, sr=utils.SAMPLING_RATE, n_mels=80, fmin=27.5, fmax=16000):\n",
    "    hop_length = int(sr * 0.01)\n",
    "    context_frames = 7  # ±70 ms implies 7 frames on each side\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "\n",
    "    # Prepare spectrograms\n",
    "    melspecs = []\n",
    "    for window_size in [int(sr * 0.023), int(sr * 0.046), int(sr * 0.093)]:\n",
    "        melspec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=window_size,\n",
    "                                                 hop_length=hop_length, n_mels=n_mels,\n",
    "                                                 fmin=fmin, fmax=fmax)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "        melspecs.append(melspec)\n",
    "\n",
    "    # Define frame step to ensure overlapping windows\n",
    "    frame_step = context_frames  # This can be adjusted based on the desired overlap\n",
    "\n",
    "    # Collect context windows for all frames\n",
    "    cnn_inputs = []\n",
    "    num_frames = melspecs[0].shape[1]\n",
    "    for idx in range(context_frames, num_frames - context_frames, frame_step):\n",
    "        context_windows = [melspec[:, idx-context_frames:idx+context_frames+1] for melspec in melspecs]\n",
    "        if not all(window.shape == context_windows[0].shape for window in context_windows):\n",
    "            continue\n",
    "        stacked_window = np.stack(context_windows, axis=-1)\n",
    "        cnn_inputs.append(stacked_window)\n",
    "\n",
    "    # Normalize the inputs\n",
    "    cnn_inputs = np.array(cnn_inputs)\n",
    "    mean = np.mean(cnn_inputs, axis=(0, 1, 2), keepdims=True)\n",
    "    std = np.std(cnn_inputs, axis=(0, 1, 2), keepdims=True)\n",
    "    cnn_inputs_normalized = (cnn_inputs - mean) / std\n",
    "\n",
    "    return cnn_inputs_normalized.reshape(cnn_inputs_normalized.shape[0], 15, 80, 3)\n",
    "\n",
    "def process_test_data(audio_paths, sr=utils.SAMPLING_RATE, n_mels=80, fmin=27.5, fmax=16000):\n",
    "    all_features = []\n",
    "\n",
    "    # Iterate through each audio file\n",
    "    for audio_path in audio_paths:\n",
    "        # Process each file\n",
    "        cnn_inputs = preprocess_test_data(\n",
    "            audio_path,\n",
    "            sr=sr,\n",
    "            n_mels=n_mels,\n",
    "            fmin=fmin,\n",
    "            fmax=fmax\n",
    "        )\n",
    "\n",
    "        # Append the results to the aggregate list\n",
    "        all_features.extend(cnn_inputs)\n",
    "\n",
    "    # Convert list to numpy array for use in machine learning models\n",
    "    return np.array(all_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T22:02:46.953433Z",
     "start_time": "2024-05-12T22:02:46.948751Z"
    }
   },
   "id": "60bef75ed45bf0bd"
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "def preprocess_onset_contexts_and_labels_balanced(audio_path, sr=utils.SAMPLING_RATE, n_mels=80, fmin=27.5, fmax=16000, onset_times=[]):\n",
    "    hop_length = int(sr * 0.01)\n",
    "    context_frames = 7  # ±70 ms implies 7 frames on each side\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "\n",
    "    # Prepare spectrograms\n",
    "    melspecs = []\n",
    "    for window_size in [int(sr * 0.023), int(sr * 0.046), int(sr * 0.093)]:\n",
    "        melspec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=window_size,\n",
    "                                                 hop_length=hop_length, n_mels=n_mels,\n",
    "                                                 fmin=fmin, fmax=fmax)\n",
    "        melspec = librosa.power_to_db(melspec)\n",
    "        melspecs.append(melspec)\n",
    "\n",
    "    # Calculate frame indices for onsets and filter for valid ones\n",
    "    frame_indices = [int(time / (hop_length / sr)) for time in onset_times]\n",
    "    valid_frames = [idx for idx in frame_indices if idx >= context_frames and idx + context_frames < melspecs[0].shape[1]]\n",
    "\n",
    "    # Collect context windows and labels for valid onsets\n",
    "    cnn_inputs = []\n",
    "    labels = []\n",
    "    for idx in valid_frames:\n",
    "        context_windows = [melspec[:, idx-context_frames:idx+context_frames+1] for melspec in melspecs]\n",
    "        # Check that all windows are of the same shape\n",
    "        if not all(window.shape == context_windows[0].shape for window in context_windows):\n",
    "            continue\n",
    "        stacked_window = np.stack(context_windows, axis=-1)\n",
    "        cnn_inputs.append(stacked_window)\n",
    "        labels.append(1)\n",
    "\n",
    "    # Select an equal number of non-onset frames\n",
    "    non_onset_frames = [i for i in range(context_frames, melspecs[0].shape[1] - context_frames)\n",
    "                        if i not in valid_frames and all(abs(i - x) > context_frames for x in valid_frames)]\n",
    "    if len(non_onset_frames) >= len(valid_frames):\n",
    "        non_onset_samples = np.random.choice(non_onset_frames, len(valid_frames), replace=False)\n",
    "    else:\n",
    "        non_onset_samples = non_onset_frames\n",
    "\n",
    "    for idx in non_onset_samples:\n",
    "        context_windows = [melspec[:, idx-context_frames:idx+context_frames+1] for melspec in melspecs]\n",
    "        if not all(window.shape == context_windows[0].shape for window in context_windows):\n",
    "            continue\n",
    "        stacked_window = np.stack(context_windows, axis=-1)\n",
    "        cnn_inputs.append(stacked_window)\n",
    "        labels.append(0)\n",
    "\n",
    "    # Shuffle and normalize\n",
    "    permutation = np.random.permutation(len(labels))\n",
    "    cnn_inputs = np.array(cnn_inputs)[permutation]\n",
    "    labels = np.array(labels)[permutation]\n",
    "    mean = np.mean(cnn_inputs, axis=(0, 1, 2), keepdims=True)\n",
    "    std = np.std(cnn_inputs, axis=(0, 1, 2), keepdims=True)\n",
    "    cnn_inputs = (cnn_inputs - mean) / std\n",
    "\n",
    "    return cnn_inputs.reshape(cnn_inputs.shape[0], 15, 80, 3), labels\n",
    "\n",
    "def process_data(audio_paths, onset_times_list, sr=utils.SAMPLING_RATE, n_mels=80, fmin=27.5, fmax=16000):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Iterate through each audio file and its corresponding onset times\n",
    "    for audio_path, onset_times in zip(audio_paths, onset_times_list):\n",
    "        # Process each file with the balanced preprocessing function\n",
    "        cnn_inputs, labels = preprocess_onset_contexts_and_labels_balanced(\n",
    "            audio_path,\n",
    "            sr=sr,\n",
    "            n_mels=n_mels,\n",
    "            fmin=fmin,\n",
    "            fmax=fmax,\n",
    "            onset_times=onset_times\n",
    "        )\n",
    "\n",
    "        # Append the results to the aggregate lists\n",
    "        all_features.extend(cnn_inputs)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    # Convert lists to numpy arrays for use in machine learning models\n",
    "    all_features = np.array(all_features)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    return all_features, all_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T21:38:16.895956Z",
     "start_time": "2024-05-12T21:38:16.887694Z"
    }
   },
   "id": "cad8315f4ea44b45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T21:34:57.980901Z",
     "start_time": "2024-05-12T21:34:57.952741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, InputLayer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(shape=(15, 80, 3)),\n",
    "    Conv2D(10, kernel_size=(7, 3), activation='tanh'),\n",
    "    MaxPooling2D(pool_size=(1, 3), strides=(1, 3)),\n",
    "    Conv2D(20, kernel_size=(3, 3), activation='tanh'),\n",
    "    MaxPooling2D(pool_size=(1, 3), strides=(1, 3)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='sigmoid'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD(learning_rate=0.05, momentum=0.45)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ],
   "id": "519bc2c5e2c9f452",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential_15\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d_30 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m9\u001B[0m, \u001B[38;5;34m78\u001B[0m, \u001B[38;5;34m10\u001B[0m)      │           \u001B[38;5;34m640\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_30 (\u001B[38;5;33mMaxPooling2D\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m9\u001B[0m, \u001B[38;5;34m26\u001B[0m, \u001B[38;5;34m10\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_31 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m24\u001B[0m, \u001B[38;5;34m20\u001B[0m)      │         \u001B[38;5;34m1,820\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_31 (\u001B[38;5;33mMaxPooling2D\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m20\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_15 (\u001B[38;5;33mFlatten\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1120\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_30 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │       \u001B[38;5;34m286,976\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_31 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m257\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,820</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1120</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">286,976</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m289,693\u001B[0m (1.11 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">289,693</span> (1.11 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m289,693\u001B[0m (1.11 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">289,693</span> (1.11 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T21:38:20.184050Z",
     "start_time": "2024-05-12T21:38:20.177667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features = df['File Path']\n",
    "labels = df['Onsets']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ],
   "id": "63df2f515fffafe2",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T21:40:41.865460Z",
     "start_time": "2024-05-12T21:38:20.589130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features_train, labels_train = process_data(X_train, y_train)\n",
    "features_test, labels_test = process_data(X_test, y_test)\n",
    "features_val, labels_val = process_data(X_val, y_val)"
   ],
   "id": "9b4e1f63fde92eee",
   "outputs": [],
   "execution_count": 156
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 46ms/step - accuracy: 0.6852 - loss: 0.5703 - val_accuracy: 0.8967 - val_loss: 0.2881\n",
      "Epoch 2/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 69ms/step - accuracy: 0.8475 - loss: 0.3499 - val_accuracy: 0.8927 - val_loss: 0.2671\n",
      "Epoch 3/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 66ms/step - accuracy: 0.8638 - loss: 0.3203 - val_accuracy: 0.8922 - val_loss: 0.2769\n",
      "Epoch 4/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 75ms/step - accuracy: 0.8736 - loss: 0.2950 - val_accuracy: 0.8857 - val_loss: 0.2628\n",
      "Epoch 5/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 124ms/step - accuracy: 0.8853 - loss: 0.2744 - val_accuracy: 0.8896 - val_loss: 0.2645\n",
      "Epoch 6/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 124ms/step - accuracy: 0.8928 - loss: 0.2597 - val_accuracy: 0.8770 - val_loss: 0.2897\n",
      "Epoch 7/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 78ms/step - accuracy: 0.8991 - loss: 0.2467 - val_accuracy: 0.9113 - val_loss: 0.2453\n",
      "Epoch 8/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 68ms/step - accuracy: 0.9041 - loss: 0.2400 - val_accuracy: 0.9155 - val_loss: 0.2344\n",
      "Epoch 9/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 78ms/step - accuracy: 0.9102 - loss: 0.2235 - val_accuracy: 0.9090 - val_loss: 0.2427\n",
      "Epoch 10/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 73ms/step - accuracy: 0.9141 - loss: 0.2206 - val_accuracy: 0.9069 - val_loss: 0.2630\n",
      "Epoch 11/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 78ms/step - accuracy: 0.9099 - loss: 0.2230 - val_accuracy: 0.9189 - val_loss: 0.2404\n",
      "Epoch 12/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 79ms/step - accuracy: 0.9175 - loss: 0.2096 - val_accuracy: 0.9221 - val_loss: 0.2261\n",
      "Epoch 13/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 108ms/step - accuracy: 0.9221 - loss: 0.1998 - val_accuracy: 0.9205 - val_loss: 0.2374\n",
      "Epoch 14/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 102ms/step - accuracy: 0.9253 - loss: 0.1965 - val_accuracy: 0.9129 - val_loss: 0.2513\n",
      "Epoch 15/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 92ms/step - accuracy: 0.9259 - loss: 0.1921 - val_accuracy: 0.9258 - val_loss: 0.2154\n",
      "Epoch 16/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 86ms/step - accuracy: 0.9267 - loss: 0.1897 - val_accuracy: 0.9270 - val_loss: 0.2109\n",
      "Epoch 17/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 89ms/step - accuracy: 0.9277 - loss: 0.1873 - val_accuracy: 0.9040 - val_loss: 0.2698\n",
      "Epoch 18/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 78ms/step - accuracy: 0.9297 - loss: 0.1791 - val_accuracy: 0.9219 - val_loss: 0.2281\n",
      "Epoch 19/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 63ms/step - accuracy: 0.9313 - loss: 0.1779 - val_accuracy: 0.9228 - val_loss: 0.2210\n",
      "Epoch 20/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 52ms/step - accuracy: 0.9356 - loss: 0.1713 - val_accuracy: 0.9249 - val_loss: 0.1988\n",
      "Epoch 21/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 66ms/step - accuracy: 0.9336 - loss: 0.1709 - val_accuracy: 0.9265 - val_loss: 0.2019\n",
      "Epoch 22/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 51ms/step - accuracy: 0.9373 - loss: 0.1664 - val_accuracy: 0.9213 - val_loss: 0.2092\n",
      "Epoch 23/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 47ms/step - accuracy: 0.9381 - loss: 0.1681 - val_accuracy: 0.9268 - val_loss: 0.1956\n",
      "Epoch 24/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9392 - loss: 0.1630 - val_accuracy: 0.9244 - val_loss: 0.2147\n",
      "Epoch 25/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9387 - loss: 0.1583 - val_accuracy: 0.9168 - val_loss: 0.2290\n",
      "Epoch 26/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 44ms/step - accuracy: 0.9409 - loss: 0.1573 - val_accuracy: 0.9260 - val_loss: 0.2102\n",
      "Epoch 27/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 44ms/step - accuracy: 0.9404 - loss: 0.1548 - val_accuracy: 0.9297 - val_loss: 0.1844\n",
      "Epoch 28/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9420 - loss: 0.1545 - val_accuracy: 0.9169 - val_loss: 0.2303\n",
      "Epoch 29/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9434 - loss: 0.1479 - val_accuracy: 0.9278 - val_loss: 0.1874\n",
      "Epoch 30/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9419 - loss: 0.1499 - val_accuracy: 0.9249 - val_loss: 0.2128\n",
      "Epoch 31/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9449 - loss: 0.1436 - val_accuracy: 0.9321 - val_loss: 0.1826\n",
      "Epoch 32/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 42ms/step - accuracy: 0.9471 - loss: 0.1429 - val_accuracy: 0.9284 - val_loss: 0.1902\n",
      "Epoch 33/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9459 - loss: 0.1405 - val_accuracy: 0.9312 - val_loss: 0.1852\n",
      "Epoch 34/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9457 - loss: 0.1436 - val_accuracy: 0.9276 - val_loss: 0.2042\n",
      "Epoch 35/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9466 - loss: 0.1428 - val_accuracy: 0.9307 - val_loss: 0.1912\n",
      "Epoch 36/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9482 - loss: 0.1364 - val_accuracy: 0.9287 - val_loss: 0.1962\n",
      "Epoch 37/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9483 - loss: 0.1357 - val_accuracy: 0.9303 - val_loss: 0.1861\n",
      "Epoch 38/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 44ms/step - accuracy: 0.9492 - loss: 0.1345 - val_accuracy: 0.9308 - val_loss: 0.1893\n",
      "Epoch 39/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 42ms/step - accuracy: 0.9493 - loss: 0.1339 - val_accuracy: 0.9307 - val_loss: 0.1912\n",
      "Epoch 40/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 42ms/step - accuracy: 0.9520 - loss: 0.1301 - val_accuracy: 0.9207 - val_loss: 0.2170\n",
      "Epoch 41/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9521 - loss: 0.1305 - val_accuracy: 0.9228 - val_loss: 0.2141\n",
      "Epoch 42/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9557 - loss: 0.1236 - val_accuracy: 0.9282 - val_loss: 0.1984\n",
      "Epoch 43/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9540 - loss: 0.1250 - val_accuracy: 0.9310 - val_loss: 0.1894\n",
      "Epoch 44/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9543 - loss: 0.1263 - val_accuracy: 0.9282 - val_loss: 0.1987\n",
      "Epoch 45/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9543 - loss: 0.1243 - val_accuracy: 0.9299 - val_loss: 0.1936\n",
      "Epoch 46/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9539 - loss: 0.1238 - val_accuracy: 0.9321 - val_loss: 0.1870\n",
      "Epoch 47/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 43ms/step - accuracy: 0.9558 - loss: 0.1216 - val_accuracy: 0.9163 - val_loss: 0.2310\n",
      "Epoch 48/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 44ms/step - accuracy: 0.9564 - loss: 0.1195 - val_accuracy: 0.9289 - val_loss: 0.1949\n",
      "Epoch 49/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9568 - loss: 0.1170 - val_accuracy: 0.9333 - val_loss: 0.1851\n",
      "Epoch 50/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9601 - loss: 0.1117 - val_accuracy: 0.9282 - val_loss: 0.2012\n",
      "Epoch 51/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 44ms/step - accuracy: 0.9583 - loss: 0.1168 - val_accuracy: 0.9289 - val_loss: 0.1992\n",
      "Epoch 52/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 44ms/step - accuracy: 0.9582 - loss: 0.1129 - val_accuracy: 0.9250 - val_loss: 0.2065\n",
      "Epoch 53/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9599 - loss: 0.1080 - val_accuracy: 0.9323 - val_loss: 0.1878\n",
      "Epoch 54/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 49ms/step - accuracy: 0.9585 - loss: 0.1138 - val_accuracy: 0.9357 - val_loss: 0.1862\n",
      "Epoch 55/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 47ms/step - accuracy: 0.9625 - loss: 0.1062 - val_accuracy: 0.9207 - val_loss: 0.2208\n",
      "Epoch 56/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 49ms/step - accuracy: 0.9622 - loss: 0.1047 - val_accuracy: 0.9300 - val_loss: 0.1951\n",
      "Epoch 57/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 47ms/step - accuracy: 0.9602 - loss: 0.1091 - val_accuracy: 0.9339 - val_loss: 0.1836\n",
      "Epoch 58/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 47ms/step - accuracy: 0.9624 - loss: 0.1042 - val_accuracy: 0.9344 - val_loss: 0.1945\n",
      "Epoch 59/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 47ms/step - accuracy: 0.9615 - loss: 0.1050 - val_accuracy: 0.9268 - val_loss: 0.2015\n",
      "Epoch 60/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9631 - loss: 0.1007 - val_accuracy: 0.9333 - val_loss: 0.1917\n",
      "Epoch 61/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9618 - loss: 0.1007 - val_accuracy: 0.9258 - val_loss: 0.2040\n",
      "Epoch 62/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9622 - loss: 0.1023 - val_accuracy: 0.9265 - val_loss: 0.2060\n",
      "Epoch 63/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9627 - loss: 0.1013 - val_accuracy: 0.9258 - val_loss: 0.2073\n",
      "Epoch 64/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9653 - loss: 0.0971 - val_accuracy: 0.9331 - val_loss: 0.1915\n",
      "Epoch 65/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9665 - loss: 0.0922 - val_accuracy: 0.9313 - val_loss: 0.1964\n",
      "Epoch 66/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9656 - loss: 0.0956 - val_accuracy: 0.9328 - val_loss: 0.1926\n",
      "Epoch 67/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 47ms/step - accuracy: 0.9654 - loss: 0.0937 - val_accuracy: 0.9295 - val_loss: 0.2030\n",
      "Epoch 68/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9666 - loss: 0.0934 - val_accuracy: 0.9342 - val_loss: 0.1992\n",
      "Epoch 69/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9677 - loss: 0.0913 - val_accuracy: 0.9261 - val_loss: 0.2164\n",
      "Epoch 70/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9667 - loss: 0.0916 - val_accuracy: 0.9236 - val_loss: 0.2214\n",
      "Epoch 71/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9670 - loss: 0.0899 - val_accuracy: 0.9316 - val_loss: 0.2052\n",
      "Epoch 72/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 47ms/step - accuracy: 0.9672 - loss: 0.0905 - val_accuracy: 0.9281 - val_loss: 0.2177\n",
      "Epoch 73/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 48ms/step - accuracy: 0.9681 - loss: 0.0886 - val_accuracy: 0.9318 - val_loss: 0.2028\n",
      "Epoch 74/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 48ms/step - accuracy: 0.9713 - loss: 0.0834 - val_accuracy: 0.9186 - val_loss: 0.2455\n",
      "Epoch 75/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 48ms/step - accuracy: 0.9699 - loss: 0.0854 - val_accuracy: 0.9316 - val_loss: 0.2051\n",
      "Epoch 76/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 48ms/step - accuracy: 0.9695 - loss: 0.0838 - val_accuracy: 0.9215 - val_loss: 0.2233\n",
      "Epoch 77/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 47ms/step - accuracy: 0.9715 - loss: 0.0828 - val_accuracy: 0.9127 - val_loss: 0.2409\n",
      "Epoch 78/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 47ms/step - accuracy: 0.9696 - loss: 0.0825 - val_accuracy: 0.9324 - val_loss: 0.2073\n",
      "Epoch 79/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9720 - loss: 0.0811 - val_accuracy: 0.9281 - val_loss: 0.2148\n",
      "Epoch 80/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9725 - loss: 0.0803 - val_accuracy: 0.9228 - val_loss: 0.2316\n",
      "Epoch 81/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 48ms/step - accuracy: 0.9735 - loss: 0.0764 - val_accuracy: 0.9313 - val_loss: 0.2108\n",
      "Epoch 82/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9726 - loss: 0.0772 - val_accuracy: 0.9284 - val_loss: 0.2186\n",
      "Epoch 83/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9741 - loss: 0.0748 - val_accuracy: 0.9150 - val_loss: 0.2446\n",
      "Epoch 84/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9739 - loss: 0.0766 - val_accuracy: 0.9284 - val_loss: 0.2187\n",
      "Epoch 85/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9738 - loss: 0.0733 - val_accuracy: 0.9245 - val_loss: 0.2302\n",
      "Epoch 86/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 50ms/step - accuracy: 0.9766 - loss: 0.0735 - val_accuracy: 0.9247 - val_loss: 0.2325\n",
      "Epoch 87/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 56ms/step - accuracy: 0.9771 - loss: 0.0721 - val_accuracy: 0.9284 - val_loss: 0.2273\n",
      "Epoch 88/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 48ms/step - accuracy: 0.9757 - loss: 0.0714 - val_accuracy: 0.9323 - val_loss: 0.2134\n",
      "Epoch 89/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 47ms/step - accuracy: 0.9764 - loss: 0.0713 - val_accuracy: 0.9318 - val_loss: 0.2251\n",
      "Epoch 90/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 48ms/step - accuracy: 0.9751 - loss: 0.0766 - val_accuracy: 0.9286 - val_loss: 0.2195\n",
      "Epoch 91/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 50ms/step - accuracy: 0.9776 - loss: 0.0660 - val_accuracy: 0.9295 - val_loss: 0.2323\n",
      "Epoch 92/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 48ms/step - accuracy: 0.9771 - loss: 0.0696 - val_accuracy: 0.9282 - val_loss: 0.2230\n",
      "Epoch 93/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9772 - loss: 0.0666 - val_accuracy: 0.9299 - val_loss: 0.2346\n",
      "Epoch 94/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 49ms/step - accuracy: 0.9782 - loss: 0.0658 - val_accuracy: 0.9090 - val_loss: 0.2818\n",
      "Epoch 95/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 46ms/step - accuracy: 0.9780 - loss: 0.0661 - val_accuracy: 0.9144 - val_loss: 0.2612\n",
      "Epoch 96/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9796 - loss: 0.0629 - val_accuracy: 0.9237 - val_loss: 0.2425\n",
      "Epoch 97/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9792 - loss: 0.0642 - val_accuracy: 0.9179 - val_loss: 0.2642\n",
      "Epoch 98/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9796 - loss: 0.0616 - val_accuracy: 0.9252 - val_loss: 0.2400\n",
      "Epoch 99/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9805 - loss: 0.0586 - val_accuracy: 0.9263 - val_loss: 0.2419\n",
      "Epoch 100/100\n",
      "\u001B[1m107/107\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 45ms/step - accuracy: 0.9816 - loss: 0.0608 - val_accuracy: 0.9213 - val_loss: 0.2546\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x297b1ee20>"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_train, labels_train,\n",
    "          validation_data=(features_val, labels_val),\n",
    "          epochs=100, batch_size=256)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T21:50:16.327010Z",
     "start_time": "2024-05-12T21:40:45.852524Z"
    }
   },
   "id": "a96c6a05562f1b32"
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m432/432\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9212 - loss: 0.2474\n",
      "Test Accuracy: 0.9126656651496887\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(features_test, labels_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T21:52:30.195261Z",
     "start_time": "2024-05-12T21:52:29.368764Z"
    }
   },
   "id": "5b1c1e08c49518c8"
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "test, _, _, _= utils.load_dataset_paths(test_dataset, is_train_dataset=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T22:00:40.656087Z",
     "start_time": "2024-05-12T22:00:40.645773Z"
    }
   },
   "id": "6e3194000993e788"
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "onsets = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T22:01:20.985217Z",
     "start_time": "2024-05-12T22:01:20.979479Z"
    }
   },
   "id": "e41189918f86b44d"
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step \n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step \n",
      "\u001B[1m9/9\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step \n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step \n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "\u001B[1m5/5\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step \n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step \n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step\n",
      "\u001B[1m11/11\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step\n",
      "\u001B[1m14/14\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step\n",
      "\u001B[1m7/7\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step \n"
     ]
    }
   ],
   "source": [
    "for path in test:\n",
    "    file_name = path.split('/')[-1].replace('.wav', '')\n",
    "    t_preprocessed = preprocess_test_data(path)\n",
    "    predictions = model.predict(t_preprocessed)\n",
    "    onset_predictions = (predictions > 0.5).astype(int)\n",
    "    onsets_in_sec = frames_to_onset(onset_predictions)\n",
    "    onsets[file_name] = {'onsets': list(onsets_in_sec)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T22:04:25.068952Z",
     "start_time": "2024-05-12T22:04:03.614116Z"
    }
   },
   "id": "32faca30a79620c7"
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_filename = 'onsets_data_3.json'\n",
    "with open(json_filename, 'w') as f:\n",
    "    json.dump(onsets, f, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T22:04:49.862590Z",
     "start_time": "2024-05-12T22:04:49.851672Z"
    }
   },
   "id": "eae458c54f53819c"
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "data": {
      "text/plain": "(10844, 15, 80, 3)"
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T21:57:22.333772Z",
     "start_time": "2024-05-12T21:57:22.324003Z"
    }
   },
   "id": "f8469bd9c81c6a0b"
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m339/339\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T21:58:39.960225Z",
     "start_time": "2024-05-12T21:58:39.167242Z"
    }
   },
   "id": "85f33f94b0eec3a7"
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "onset_predictions = (predictions > 0.5).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T21:59:05.176162Z",
     "start_time": "2024-05-12T21:59:05.167918Z"
    }
   },
   "id": "9a1e5767c40bb9c3"
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1],\n       [0],\n       [0],\n       ...,\n       [0],\n       [1],\n       [0]])"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onset_predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T21:59:06.682872Z",
     "start_time": "2024-05-12T21:59:06.665034Z"
    }
   },
   "id": "c882b3834a5ebc11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d4684d3763de450e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
